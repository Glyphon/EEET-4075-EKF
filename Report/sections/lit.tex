Put broadly, localisation can be split into two categories; absolute, which measures the pose of a system directly; and relative, which uses a dead reckoning technique to estimate the pose of a system using other information. \cite{indoor} investigates methods for both. They use inertial based localisation through the use an Inertial Measurement Unit (IMU) and wheel encoders updated at a high rate to estimate the pose of the robot in question. They then use a LiDAR image at specific places on its path and match that to an already known occupancy map to adjust said pose. Both of these estimates are then fused through the use of an EKF to give a final estimate.\par
Unfortunately, occupancy maps are beyond the scope of this experiment, but \cite{beacon} describes a method for absolute pose estimation using triangulation from known landmarks. While their method uses particle filtering to calculate the estimated pose, the specifics of how the LiDAR is used in triangulation can be used in any filtering technique, including the EKF.\par
For the standard EKF to work effectively, a few assumptions are made; both the process and measurement noise are additive, and have a Gaussian distribution; the system is not heavily non-linear; and that measurements in $y_{k}$ arrive at the same time, and pertain to the current state $x_{k}$ \cite{compare}. The first two assumptions can really only be rectified by changing the system, usually unfeasible, or by using a different filtering algorithm altogether, such as the Unscented Kalman Filter or Particle Filter. However, both of these increase the computational complexity of the filtering.\par
The last assumption however, can be solved while still using the EKF effectively. With the use of a multirate, multisensor system such as the one used within, \cite{delayed} includes a number of methods with which to account for this delayed measurement. The most straightforward way to accomplish this is to simply go back to the state in which the delayed measurement pertains to and recalculate all states from that point till the current state. This is quite resource intensive, requiring all states and variables to be held in memory, and calculated twice. To overcome this, \cite{alex} proposed just using the linearized portions of the EKF, the Kalman Gain and Prediction Covariance matrices, to fuse the current (primary) measurement and the delayed (secondary) measurement. The advantages of this system is that it is very efficient, both in memory and computational complexity, nor does it introduce and systematic error to the system. The drawback to this solution is that the states between each secondary measurement are not optimal. A solution does exist to solve this optimality issue, which runs the recalculation part of \cite{alex}'s method in parallel to the primary EKF, and uses the parellel filter to re-initialize the primary filter. \cite{delayed} shows that this method is as computationally expensive as just recalculating all states.\par
Being that the methods described pertain to fusing two sensors, \cite{multi} states that multiple EKFs can simply be cascaded, with the output of one EKF being used as the input to another. In this way, any number of measurements with differing update rates and delays can be fused at the cost of computational complexity. As keeping computational complexity to a minimum was a goal of this experiment, using Alexander's Method to fuse the delayed measurement with a standard EKF was the chosen method. While not optimal, it did present the best compromise between accuracy and complexity of the solutions presented. In a system where a higher update rate is likely to have more of an impact to system stability and accuracy than a more optimal filtering technique, it does appear the best choice.